{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/hak9238/hak9238/blob/main/koalpaca-polyglot-12.8b.ipynb)\n"
      ],
      "metadata": {
        "id": "sQeiNsqiKFgt"
      },
      "id": "sQeiNsqiKFgt"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0900aaea-356c-4c1b-941f-66e5d99c65e9",
      "metadata": {
        "colab": {
          "referenced_widgets": [
            "d6d5aaf81493405ea95e6c578eae7198"
          ]
        },
        "id": "0900aaea-356c-4c1b-941f-66e5d99c65e9",
        "outputId": "3cbed443-675f-42cd-edee-d8e7a027f380"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/opt/anaconda3/lib/python3.12/site-packages/accelerate/utils/modeling.py:1536: UserWarning: Current model requires 18876808.0 bytes of buffer for offloaded layers, which seems does not fit any GPU's remaining memory. If you are experiencing a OOM later, please consider using offload_buffers=True.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "d6d5aaf81493405ea95e6c578eae7198",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Loading checkpoint shards:   0%|          | 0/28 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some parameters are on the meta device because they were offloaded to the disk.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "âœ… KoAlpaca-Polyglot-12.8B ëª¨ë¸ì´ ì„±ê³µì ìœ¼ë¡œ ë¡œë“œë˜ì—ˆìŠµë‹ˆë‹¤!\n"
          ]
        }
      ],
      "source": [
        "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
        "\n",
        "MODEL_NAME = \"beomi/KoAlpaca-Polyglot-12.8B\"\n",
        "offload_folder = \"/Users/hakhyunlee/offload\"  # ì“°ê¸° ê°€ëŠ¥í•œ ê²½ë¡œë¡œ ì„¤ì •\n",
        "\n",
        "# í† í¬ë‚˜ì´ì € ë¡œë“œ\n",
        "tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME)\n",
        "\n",
        "# FP16ìœ¼ë¡œ ëª¨ë¸ ë¡œë“œí•˜ê³ , device_mapì„ autoë¡œ ì„¤ì •í•˜ì—¬ ìžì›ì„ ìžë™ìœ¼ë¡œ ë¶„ë°°\n",
        "model = AutoModelForCausalLM.from_pretrained(\n",
        "    MODEL_NAME,\n",
        "    device_map=\"auto\",  # GPU/CPU ìžì›ì„ ìžë™ìœ¼ë¡œ ë¶„ë°°\n",
        "    torch_dtype=\"float16\",  # FP16 ì‚¬ìš©ìœ¼ë¡œ ë©”ëª¨ë¦¬ ì ˆì•½\n",
        "    offload_folder=offload_folder  # ë©”ëª¨ë¦¬ ë¶€ì¡± ì‹œ ë””ìŠ¤í¬ë¡œ ì¼ë¶€ ì˜¤í”„ë¡œë“œ\n",
        ")\n",
        "\n",
        "print(\"âœ… KoAlpaca-Polyglot-12.8B ëª¨ë¸ì´ ì„±ê³µì ìœ¼ë¡œ ë¡œë“œë˜ì—ˆìŠµë‹ˆë‹¤!\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7615c0a5",
      "metadata": {
        "id": "7615c0a5",
        "outputId": "c1302122-ed8e-4306-9a99-96ea9838f939"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "ðŸ“… 20250101 ë‚ ì§œì˜ ê¸°ì‚¬ë¥¼ ìˆ˜ì§‘í•©ë‹ˆë‹¤...\n",
            "ðŸ—‚ï¸ 'ì •ì¹˜' ì¹´í…Œê³ ë¦¬ì˜ ê¸°ì‚¬ë¥¼ ìˆ˜ì§‘í•©ë‹ˆë‹¤...\n",
            "ðŸ—‚ï¸ 'ê²½ì œ' ì¹´í…Œê³ ë¦¬ì˜ ê¸°ì‚¬ë¥¼ ìˆ˜ì§‘í•©ë‹ˆë‹¤...\n",
            "ðŸ—‚ï¸ 'ì‚¬íšŒ' ì¹´í…Œê³ ë¦¬ì˜ ê¸°ì‚¬ë¥¼ ìˆ˜ì§‘í•©ë‹ˆë‹¤...\n",
            "ðŸ—‚ï¸ 'ìƒí™œ/ë¬¸í™”' ì¹´í…Œê³ ë¦¬ì˜ ê¸°ì‚¬ë¥¼ ìˆ˜ì§‘í•©ë‹ˆë‹¤...\n",
            "ðŸ—‚ï¸ 'ì„¸ê³„' ì¹´í…Œê³ ë¦¬ì˜ ê¸°ì‚¬ë¥¼ ìˆ˜ì§‘í•©ë‹ˆë‹¤...\n",
            "ðŸ—‚ï¸ 'IT/ê³¼í•™' ì¹´í…Œê³ ë¦¬ì˜ ê¸°ì‚¬ë¥¼ ìˆ˜ì§‘í•©ë‹ˆë‹¤...\n",
            "ðŸ—‚ï¸ 'ì˜¤í”¼ë‹ˆì–¸' ì¹´í…Œê³ ë¦¬ì˜ ê¸°ì‚¬ë¥¼ ìˆ˜ì§‘í•©ë‹ˆë‹¤...\n",
            "ðŸ—‚ï¸ 'í¬í† ' ì¹´í…Œê³ ë¦¬ì˜ ê¸°ì‚¬ë¥¼ ìˆ˜ì§‘í•©ë‹ˆë‹¤...\n",
            "ðŸ—‚ï¸ 'TV' ì¹´í…Œê³ ë¦¬ì˜ ê¸°ì‚¬ë¥¼ ìˆ˜ì§‘í•©ë‹ˆë‹¤...\n",
            "ðŸ“… 20250102 ë‚ ì§œì˜ ê¸°ì‚¬ë¥¼ ìˆ˜ì§‘í•©ë‹ˆë‹¤...\n",
            "ðŸ—‚ï¸ 'ì •ì¹˜' ì¹´í…Œê³ ë¦¬ì˜ ê¸°ì‚¬ë¥¼ ìˆ˜ì§‘í•©ë‹ˆë‹¤...\n",
            "ðŸ—‚ï¸ 'ê²½ì œ' ì¹´í…Œê³ ë¦¬ì˜ ê¸°ì‚¬ë¥¼ ìˆ˜ì§‘í•©ë‹ˆë‹¤...\n",
            "ðŸ—‚ï¸ 'ì‚¬íšŒ' ì¹´í…Œê³ ë¦¬ì˜ ê¸°ì‚¬ë¥¼ ìˆ˜ì§‘í•©ë‹ˆë‹¤...\n",
            "ðŸ—‚ï¸ 'ìƒí™œ/ë¬¸í™”' ì¹´í…Œê³ ë¦¬ì˜ ê¸°ì‚¬ë¥¼ ìˆ˜ì§‘í•©ë‹ˆë‹¤...\n",
            "ðŸ—‚ï¸ 'ì„¸ê³„' ì¹´í…Œê³ ë¦¬ì˜ ê¸°ì‚¬ë¥¼ ìˆ˜ì§‘í•©ë‹ˆë‹¤...\n",
            "ðŸ—‚ï¸ 'IT/ê³¼í•™' ì¹´í…Œê³ ë¦¬ì˜ ê¸°ì‚¬ë¥¼ ìˆ˜ì§‘í•©ë‹ˆë‹¤...\n",
            "ðŸ—‚ï¸ 'ì˜¤í”¼ë‹ˆì–¸' ì¹´í…Œê³ ë¦¬ì˜ ê¸°ì‚¬ë¥¼ ìˆ˜ì§‘í•©ë‹ˆë‹¤...\n",
            "ðŸ—‚ï¸ 'í¬í† ' ì¹´í…Œê³ ë¦¬ì˜ ê¸°ì‚¬ë¥¼ ìˆ˜ì§‘í•©ë‹ˆë‹¤...\n",
            "ðŸ—‚ï¸ 'TV' ì¹´í…Œê³ ë¦¬ì˜ ê¸°ì‚¬ë¥¼ ìˆ˜ì§‘í•©ë‹ˆë‹¤...\n",
            "ðŸ“… 20250103 ë‚ ì§œì˜ ê¸°ì‚¬ë¥¼ ìˆ˜ì§‘í•©ë‹ˆë‹¤...\n",
            "ðŸ—‚ï¸ 'ì •ì¹˜' ì¹´í…Œê³ ë¦¬ì˜ ê¸°ì‚¬ë¥¼ ìˆ˜ì§‘í•©ë‹ˆë‹¤...\n",
            "ðŸ—‚ï¸ 'ê²½ì œ' ì¹´í…Œê³ ë¦¬ì˜ ê¸°ì‚¬ë¥¼ ìˆ˜ì§‘í•©ë‹ˆë‹¤...\n",
            "ðŸ—‚ï¸ 'ì‚¬íšŒ' ì¹´í…Œê³ ë¦¬ì˜ ê¸°ì‚¬ë¥¼ ìˆ˜ì§‘í•©ë‹ˆë‹¤...\n",
            "ðŸ—‚ï¸ 'ìƒí™œ/ë¬¸í™”' ì¹´í…Œê³ ë¦¬ì˜ ê¸°ì‚¬ë¥¼ ìˆ˜ì§‘í•©ë‹ˆë‹¤...\n",
            "ðŸ—‚ï¸ 'ì„¸ê³„' ì¹´í…Œê³ ë¦¬ì˜ ê¸°ì‚¬ë¥¼ ìˆ˜ì§‘í•©ë‹ˆë‹¤...\n",
            "ðŸ—‚ï¸ 'IT/ê³¼í•™' ì¹´í…Œê³ ë¦¬ì˜ ê¸°ì‚¬ë¥¼ ìˆ˜ì§‘í•©ë‹ˆë‹¤...\n",
            "ðŸ—‚ï¸ 'ì˜¤í”¼ë‹ˆì–¸' ì¹´í…Œê³ ë¦¬ì˜ ê¸°ì‚¬ë¥¼ ìˆ˜ì§‘í•©ë‹ˆë‹¤...\n",
            "ðŸ—‚ï¸ 'í¬í† ' ì¹´í…Œê³ ë¦¬ì˜ ê¸°ì‚¬ë¥¼ ìˆ˜ì§‘í•©ë‹ˆë‹¤...\n",
            "ðŸ—‚ï¸ 'TV' ì¹´í…Œê³ ë¦¬ì˜ ê¸°ì‚¬ë¥¼ ìˆ˜ì§‘í•©ë‹ˆë‹¤...\n",
            "ðŸ“° ë‰´ìŠ¤ ë°ì´í„°ê°€ '/Users/hakhyunlee/Desktop/ëŒ€í•™ì›/ì‹¤ìŠµ ì˜ˆì œ/ë‰´ìŠ¤ íŒŒì¼/ë‰´ìŠ¤_20250101_to_20250103.csv'ì— ì„±ê³µì ìœ¼ë¡œ ì €ìž¥ë˜ì—ˆìŠµë‹ˆë‹¤.\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import requests\n",
        "from bs4 import BeautifulSoup\n",
        "import pandas as pd\n",
        "\n",
        "# í¬ë¡¤ë§í•  ë‚ ì§œ ë²”ìœ„ ì„¤ì • (2025ë…„ 1ì›” 1ì¼ë¶€í„° 1ì›” 3ì¼ê¹Œì§€)\n",
        "start_date = '20250101'\n",
        "end_date = '20250103'\n",
        "date_range = pd.date_range(start=start_date, end=end_date)\n",
        "\n",
        "# ë„¤ì´ë²„ ë‰´ìŠ¤ ì¹´í…Œê³ ë¦¬ ì½”ë“œ ì„¤ì •\n",
        "categories = {\n",
        "    'ì •ì¹˜': '100',\n",
        "    'ê²½ì œ': '101',\n",
        "    'ì‚¬íšŒ': '102',\n",
        "    'ìƒí™œ/ë¬¸í™”': '103',\n",
        "    'ì„¸ê³„': '104',\n",
        "    'IT/ê³¼í•™': '105',\n",
        "    'ì˜¤í”¼ë‹ˆì–¸': '110',\n",
        "    'í¬í† ': '115',\n",
        "    'TV': '120'\n",
        "}\n",
        "base_url = 'https://news.naver.com/main/list.naver'\n",
        "\n",
        "# HTTP ìš”ì²­ í—¤ë” ì„¤ì •\n",
        "headers = {\n",
        "    'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) '\n",
        "                  'AppleWebKit/537.36 (KHTML, like Gecko) '\n",
        "                  'Chrome/58.0.3029.110 Safari/537.3'\n",
        "}\n",
        "\n",
        "# ì „ì²´ ë‰´ìŠ¤ ë°ì´í„°ë¥¼ ì €ìž¥í•  ë¦¬ìŠ¤íŠ¸ ì´ˆê¸°í™”\n",
        "all_news = []\n",
        "\n",
        "# ê° ë‚ ì§œì™€ ì¹´í…Œê³ ë¦¬ì— ëŒ€í•´ í¬ë¡¤ë§ ìˆ˜í–‰\n",
        "for single_date in date_range:\n",
        "    date_str = single_date.strftime('%Y%m%d')\n",
        "    print(f\"ðŸ“… {date_str} ë‚ ì§œì˜ ê¸°ì‚¬ë¥¼ ìˆ˜ì§‘í•©ë‹ˆë‹¤...\")\n",
        "\n",
        "    for category_name, category_code in categories.items():\n",
        "        print(f\"ðŸ—‚ï¸ '{category_name}' ì¹´í…Œê³ ë¦¬ì˜ ê¸°ì‚¬ë¥¼ ìˆ˜ì§‘í•©ë‹ˆë‹¤...\")\n",
        "\n",
        "        titles = []\n",
        "        contents = []\n",
        "        links_set = set()  # ì¤‘ë³µ ë°©ì§€ë¥¼ ìœ„í•œ ì§‘í•©\n",
        "\n",
        "        # íŽ˜ì´ì§€ ë²ˆí˜¸ë¥¼ 1ë¶€í„° 3ê¹Œì§€ ìˆœíšŒ\n",
        "        for page in range(1, 4):\n",
        "            # í˜„ìž¬ íŽ˜ì´ì§€ì˜ URL ìƒì„±\n",
        "            params = {\n",
        "                'mode': 'LS2D',\n",
        "                'mid': 'shm',\n",
        "                'sid1': category_code,\n",
        "                'date': date_str,\n",
        "                'page': page\n",
        "            }\n",
        "            response = requests.get(base_url, headers=headers, params=params)\n",
        "            soup = BeautifulSoup(response.text, 'html.parser')\n",
        "\n",
        "            # í˜„ìž¬ íŽ˜ì´ì§€ì˜ ë‰´ìŠ¤ ê¸°ì‚¬ ë§í¬ ì¶”ì¶œ\n",
        "            articles = soup.select('.newsflash_body .type06_headline li dl dt a')\n",
        "            links = [article['href'] for article in articles]\n",
        "\n",
        "            # ê° ê¸°ì‚¬ì— ì ‘ê·¼í•˜ì—¬ ì œëª©ê³¼ ë³¸ë¬¸ ì¶”ì¶œ\n",
        "            for link in links:\n",
        "                if link not in links_set:\n",
        "                    links_set.add(link)\n",
        "                    article_response = requests.get(link, headers=headers)\n",
        "                    article_soup = BeautifulSoup(article_response.text, 'html.parser')\n",
        "\n",
        "                    # ì œëª© ì¶”ì¶œ\n",
        "                    title_element = article_soup.find('h2', {'id': 'title_area'})\n",
        "                    if title_element:\n",
        "                        title = title_element.get_text(strip=True)\n",
        "                    else:\n",
        "                        title = 'ì œëª©ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.'\n",
        "\n",
        "                    # ë³¸ë¬¸ ì¶”ì¶œ\n",
        "                    content_element = article_soup.find('div', {'id': 'newsct_article'})\n",
        "                    if content_element:\n",
        "                        content = content_element.get_text(strip=True)\n",
        "                    else:\n",
        "                        content = 'ë³¸ë¬¸ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.'\n",
        "\n",
        "                    titles.append(title)\n",
        "                    contents.append(content)\n",
        "\n",
        "        # ë°ì´í„°í”„ë ˆìž„ ìƒì„± ë° ì¤‘ë³µ ì œê±°\n",
        "        news_df = pd.DataFrame({\n",
        "            'date': date_str,\n",
        "            'category': category_name,\n",
        "            'title': titles,\n",
        "            'content': contents\n",
        "        })\n",
        "        news_df.drop_duplicates(subset=['title'], inplace=True)\n",
        "\n",
        "        # ìˆ˜ì§‘í•œ ë°ì´í„°ë¥¼ ë¦¬ìŠ¤íŠ¸ì— ì¶”ê°€\n",
        "        all_news.append(news_df)\n",
        "\n",
        "# ëª¨ë“  ë‚ ì§œì™€ ì¹´í…Œê³ ë¦¬ì˜ ë°ì´í„°ë¥¼ í•˜ë‚˜ì˜ ë°ì´í„°í”„ë ˆìž„ìœ¼ë¡œ ê²°í•©\n",
        "final_news_df = pd.concat(all_news, ignore_index=True)\n",
        "\n",
        "# ì €ìž¥í•  í´ë” ê²½ë¡œ ì„¤ì •\n",
        "save_folder = '/Users/hakhyunlee/Desktop/ëŒ€í•™ì›/ì‹¤ìŠµ ì˜ˆì œ/ë‰´ìŠ¤ íŒŒì¼'\n",
        "\n",
        "# í´ë”ê°€ ì¡´ìž¬í•˜ì§€ ì•Šìœ¼ë©´ ìƒì„±\n",
        "if not os.path.exists(save_folder):\n",
        "    os.makedirs(save_folder)\n",
        "\n",
        "# íŒŒì¼ëª… ì„¤ì •\n",
        "file_name = f'ë‰´ìŠ¤_{start_date}_to_{end_date}.csv'\n",
        "save_path = os.path.join(save_folder, file_name)\n",
        "\n",
        "# CSV íŒŒì¼ë¡œ ì €ìž¥\n",
        "final_news_df.to_csv(save_path, index=False, encoding='utf-8-sig')\n",
        "\n",
        "print(f\"ðŸ“° ë‰´ìŠ¤ ë°ì´í„°ê°€ '{save_path}'ì— ì„±ê³µì ìœ¼ë¡œ ì €ìž¥ë˜ì—ˆìŠµë‹ˆë‹¤.\")\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1085b1da",
      "metadata": {
        "id": "1085b1da"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f8429c35-6ed8-4cf0-8a1f-f7f7437d0478",
      "metadata": {
        "id": "f8429c35-6ed8-4cf0-8a1f-f7f7437d0478"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.7"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}